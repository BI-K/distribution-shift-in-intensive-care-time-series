{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce60d06b",
   "metadata": {},
   "source": [
    "# Distance Measures between Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4167f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa231463",
   "metadata": {},
   "source": [
    "## Distance Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8a7c40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e58c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "def kl_divergence_pairwise(source, target):\n",
    "    min_val = min(source.min(), target.min())\n",
    "    max_val = max(source.max(), target.max())\n",
    "    bins = 100\n",
    "    hist_source, bin_edges = np.histogram(source, bins=bins, range=(min_val, max_val), density=True)\n",
    "    hist_target, _ = np.histogram(target, bins=bin_edges, density=True)\n",
    "    hist_source += 1e-10\n",
    "    hist_target += 1e-10\n",
    "    kl = entropy(hist_source, hist_target)\n",
    "    return kl, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea0276e",
   "metadata": {},
   "source": [
    "## Overarching Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90b26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_distance(distance_function, df1, df2, df3=None):\n",
    "    # one value for each column\n",
    "    results = {}\n",
    "    for col in df1.columns:\n",
    "        stat1, p_value1 = distance_function(df1[col], df2[col])\n",
    "        if df3 is not None:\n",
    "            stat2, p_value2 = distance_function(df1[col], df3[col])\n",
    "            # source test vs target all\n",
    "            stat3, p_value3 = distance_function(df2[col], df3[col])\n",
    "            results[col] = {\n",
    "                \"source_train_vs_source_test\":  stat1,\n",
    "                \"source_train_vs_target_test\": stat2,\n",
    "                \"source_test_vs_target_test\": stat3\n",
    "            }\n",
    "        else:\n",
    "            results[col] = {\n",
    "                \"source_vs_target\": stat1\n",
    "            }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8409823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_distance_classwise(distance_function, df1_class1, df1_class2, df2_class1, df2_class2, df3_class1=None, df3_class2=None):\n",
    "    # one value for each column\n",
    "    results = {}\n",
    "    for col in df1_class1.columns:\n",
    "        stat1_2_class1, p_value1 = distance_function(df1_class1[col], df2_class1[col])\n",
    "        stat1_2_class2, p_value1 = distance_function(df1_class2[col], df2_class2[col])\n",
    "        if df3_class1 is not None and df3_class2 is not None:\n",
    "            stat2_2_class1, p_value2 = distance_function(df1_class1[col], df3_class1[col])\n",
    "            stat2_2_class2, p_value2 = distance_function(df1_class2[col], df3_class2[col])\n",
    "            stat3_2_class1, p_value3 = distance_function(df2_class1[col], df3_class1[col])\n",
    "            stat3_2_class2, p_value3 = distance_function(df2_class2[col], df3_class2[col])\n",
    "            results[col] = {\n",
    "                \"source_train_vs_source_test_class1\":  stat1_2_class1,\n",
    "                \"source_train_vs_source_test_class2\":  stat1_2_class2,\n",
    "                \"source_train_vs_target_test_class1\":  stat2_2_class1,\n",
    "                \"source_train_vs_target_test_class2\":  stat2_2_class2,\n",
    "                \"source_test_vs_target_test_class1\":  stat3_2_class1,\n",
    "                \"source_test_vs_target_test_class2\":  stat3_2_class2\n",
    "            }\n",
    "        else:\n",
    "            results[col] = {\n",
    "                \"source_train_vs_source_test_class1\":  stat1_2_class1,\n",
    "                \"source_train_vs_source_test_class2\":  stat1_2_class2,\n",
    "            }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be3fe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(source_label, target_label, channel =''):\n",
    "    source_train = torch.load(f'../data/train_{source_label}_cleaned{channel}.pt', weights_only=False)\n",
    "    source_test = torch.load(f'../data/test_{source_label}_cleaned{channel}.pt', weights_only=False)\n",
    "\n",
    "    # huh they look exactly the same\n",
    "    target_train = torch.load(f'../data/train_{target_label}_cleaned{channel}.pt', weights_only=False)\n",
    "    target_test = torch.load(f'../data/test_{target_label}_cleaned{channel}.pt', weights_only=False)\n",
    "\n",
    "    return source_train, source_test, target_train, target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c53293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_distance_source_train_vs_source_test_vs_target_all(label_source, label_target, distance_function):\n",
    "    # here we take an average overt time for each channel!!!\n",
    "\n",
    "    source_train, source_test, target_train, target_test = load_data(label_source, label_target)\n",
    "\n",
    "    source_samples_train = []\n",
    "    source_samples_test = []\n",
    "    source_train_samples = np.array(source_train[\"samples\"])\n",
    "    source_test_samples = np.array(source_test[\"samples\"])\n",
    "    for sample in source_train_samples:\n",
    "        # average across time dimension\n",
    "        sample_avg = [sample[:,channel_idx].mean().item() for channel_idx in range(0,6)]\n",
    "        source_samples_train.append(sample_avg)\n",
    "    source_train_df = pd.DataFrame(source_samples_train, columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\", \"NBPMean\", \"SpO2\"])\n",
    "\n",
    "    for sample in source_test_samples:\n",
    "        sample_avg = [sample[:,channel_idx].mean().item() for channel_idx in range(0,6)]\n",
    "        source_samples_test.append(sample_avg)\n",
    "    source_test_df = pd.DataFrame(source_samples_test, columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\", \"NBPMean\", \"SpO2\"])\n",
    "\n",
    "    # merge all target samples \n",
    "    target_samples_test = []\n",
    "    target_test_samples = np.array(target_test[\"samples\"])\n",
    "    for sample in target_test_samples:\n",
    "        sample_avg = [sample[:,channel_idx].mean().item() for channel_idx in range(0,6)]\n",
    "        target_samples_test.append(sample_avg)\n",
    "    for sample in np.array(target_train[\"samples\"]):\n",
    "        sample_avg = [sample[:,channel_idx].mean().item() for channel_idx in range(0,6)]\n",
    "        target_samples_test.append(sample_avg)\n",
    "        \n",
    "    target_test_df = pd.DataFrame(target_samples_test, columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\", \"NBPMean\", \"SpO2\"])\n",
    "\n",
    "    distance_measures_features = measure_distance(distance_function, source_train_df, source_test_df, target_test_df)\n",
    "    \n",
    "    distance_measures_features_df = pd.DataFrame(distance_measures_features)\n",
    "    distance_measures_features_df.columns = [f\"feature_{col}\" for col in distance_measures_features_df.columns]\n",
    "    distance_measures_features_df = distance_measures_features_df.transpose()\n",
    "    # add a row with the mean across features\n",
    "    # aggregation is tricky here, but let's keep it in addition to individual channels\n",
    "    distance_measures_features_df.loc[\"features_sum\"] = distance_measures_features_df.sum()\n",
    "    distance_measures_features_df.loc[\"features_mean\"] = distance_measures_features_df.drop(index=[\"features_sum\"], errors=\"ignore\").mean()\n",
    "    distance_measures_features_df.loc[\"features_max\"] = distance_measures_features_df.drop(index=[\"features_sum\", \"features_mean\"], errors=\"ignore\").max()\n",
    "\n",
    "    # load labels\n",
    "    source_train_labels = source_train[\"labels\"].tolist()\n",
    "    source_train_labels = [entry[0] for entry in source_train_labels]\n",
    "    source_train_labels_df = pd.DataFrame(source_train_labels, columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\", \"NBPMean\", \"SpO2\"])\n",
    "    source_train_labels_df = source_train_labels_df.drop(columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\"])\n",
    "\n",
    "    source_test_labels = source_test[\"labels\"].tolist()\n",
    "    source_test_labels = [entry[0] for entry in source_test_labels]\n",
    "    source_test_labels_df = pd.DataFrame(source_test_labels, columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\", \"NBPMean\", \"SpO2\"])\n",
    "    source_test_labels_df = source_test_labels_df.drop(columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\"])\n",
    "\n",
    "    # we evaluate on entire target set\n",
    "    target_test_labels = target_train[\"labels\"].tolist()\n",
    "    for label in target_test[\"labels\"]:\n",
    "        target_test_labels.append(label)\n",
    "    target_test_labels = [entry[0] for entry in target_test_labels]\n",
    "    target_test_labels_df = pd.DataFrame(target_test_labels, columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\", \"NBPMean\", \"SpO2\"])\n",
    "    target_test_labels_df = target_test_labels_df.drop(columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\"])\n",
    "    \n",
    "    distance_measures_labels = measure_distance(distance_function, source_train_labels_df, source_test_labels_df, target_test_labels_df)\n",
    "    distance_measures_labels_df = pd.DataFrame(distance_measures_labels)\n",
    "    distance_measures_labels_df.columns = [f\"label_{col}\" for col in distance_measures_labels_df.columns]\n",
    "    distance_measures_labels_df = distance_measures_labels_df.transpose()\n",
    "\n",
    "    # append the two dataframes\n",
    "    distance_measures_all_df = pd.concat([distance_measures_features_df, distance_measures_labels_df], axis=0)\n",
    "    distance_measures_all_df.loc[\"features_sum_SpO2_label_sum\"] = distance_measures_features_df.loc[\"features_sum\"] + distance_measures_labels_df.loc[\"label_SpO2\"]\n",
    "    distance_measures_all_df.loc[\"features_mean_SpO2_label_sum\"] = distance_measures_features_df.loc[\"features_mean\"] + distance_measures_labels_df.loc[\"label_SpO2\"]\n",
    "    distance_measures_all_df.loc[\"features_max_SpO2_label_sum\"] = distance_measures_features_df.loc[\"features_max\"] + distance_measures_labels_df.loc[\"label_SpO2\"]\n",
    "    distance_measures_all_df.loc[\"features_sum_NBPMean_label_sum\"] = distance_measures_features_df.loc[\"features_sum\"] + distance_measures_labels_df.loc[\"label_NBPMean\"]\n",
    "    distance_measures_all_df.loc[\"features_mean_NBPMean_label_sum\"] = distance_measures_features_df.loc[\"features_mean\"] + distance_measures_labels_df.loc[\"label_NBPMean\"]\n",
    "    distance_measures_all_df.loc[\"features_max_NBPMean_label_sum\"] = distance_measures_features_df.loc[\"features_max\"] + distance_measures_labels_df.loc[\"label_NBPMean\"]\n",
    "    return distance_measures_all_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22468e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_distance_source_train_vs_source_test_vs_target_all_classwise(label_source, label_target, class_label, distance_function):\n",
    "\n",
    "\n",
    "    source_train = torch.load(f'../data/train_{label_source}_cleaned.pt', weights_only=False)\n",
    "    source_test = torch.load(f'../data/test_{label_source}_cleaned.pt', weights_only=False)\n",
    "\n",
    "    target_train = torch.load(f'../data/train_{label_target}_cleaned.pt', weights_only=False)\n",
    "    target_test = torch.load(f'../data/test_{label_target}_cleaned.pt', weights_only=False)\n",
    "\n",
    "    if class_label == \"Hypotension\":\n",
    "        threshold = 65\n",
    "        label_idx = 4\n",
    "    else:\n",
    "        threshold = 90\n",
    "        label_idx = 5\n",
    "\n",
    "    source_samples_train_class1 = []\n",
    "    source_samples_train_class2 = []\n",
    "    source_labels_train_class1 = []\n",
    "    source_labels_train_class2 = []\n",
    "    source_samples_test_class1 = []\n",
    "    source_labels_test_class1 = []\n",
    "    source_samples_test_class2 = []\n",
    "    source_labels_test_class2 = []\n",
    "    for idx in range(len(source_train[\"samples\"])):\n",
    "        # average across time dimension\n",
    "        sample_avg = [source_train[\"samples\"][idx][:,channel_idx].mean().item() for channel_idx in range(0,6)]\n",
    "        if source_train[\"labels\"][idx, 0, label_idx] < threshold:\n",
    "            source_samples_train_class1.append(sample_avg)\n",
    "            source_labels_train_class1.append(source_train[\"labels\"][idx][0])\n",
    "        else:\n",
    "            source_samples_train_class2.append(sample_avg)\n",
    "            source_labels_train_class2.append(source_train[\"labels\"][idx][0])\n",
    "    source_train_class1_df = pd.DataFrame(source_samples_train_class1, columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\", \"NBPMean\", \"SpO2\"])\n",
    "    source_train_class2_df = pd.DataFrame(source_samples_train_class2, columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\", \"NBPMean\", \"SpO2\"])\n",
    "    source_train_labels_class1_df = pd.DataFrame(source_labels_train_class1, columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\", \"NBPMean\", \"SpO2\"])\n",
    "    source_train_labels_class1_df = source_train_labels_class1_df.drop(columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\"])\n",
    "    source_train_labels_class2_df = pd.DataFrame(source_labels_train_class2, columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\", \"NBPMean\", \"SpO2\"])\n",
    "    source_train_labels_class2_df = source_train_labels_class2_df.drop(columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\"])\n",
    "\n",
    "    for idx in range(len(source_test[\"samples\"])):\n",
    "        sample_avg = [source_test[\"samples\"][idx][:,channel_idx].mean().item() for channel_idx in range(0,6)]\n",
    "        if source_test[\"labels\"][idx, 0, label_idx] < threshold:\n",
    "            source_samples_test_class1.append(sample_avg)\n",
    "            source_labels_test_class1.append(source_test[\"labels\"][idx][0])\n",
    "        else:\n",
    "            source_samples_test_class2.append(sample_avg)\n",
    "            source_labels_test_class2.append(source_test[\"labels\"][idx][0])\n",
    "    source_test_class1_df = pd.DataFrame(source_samples_test_class1, columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\", \"NBPMean\", \"SpO2\"])\n",
    "    source_test_class2_df = pd.DataFrame(source_samples_test_class2, columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\", \"NBPMean\", \"SpO2\"])\n",
    "    source_test_labels_class1_df = pd.DataFrame(source_labels_test_class1, columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\", \"NBPMean\", \"SpO2\"])\n",
    "    source_test_labels_class1_df = source_test_labels_class1_df.drop(columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\"])\n",
    "    source_test_labels_class2_df = pd.DataFrame(source_labels_test_class2, columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\", \"NBPMean\", \"SpO2\"])\n",
    "    source_test_labels_class2_df = source_test_labels_class2_df.drop(columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\"])\n",
    "\n",
    "    target_samples_test_class1 = []\n",
    "    target_samples_test_class2 = []\n",
    "    target_labels_test_class1 = []\n",
    "    target_labels_test_class2 = []\n",
    "    target_test_samples = np.array(target_test[\"samples\"])\n",
    "    for idx in range(len(target_test_samples)):\n",
    "        sample_avg = [target_test_samples[idx][:,channel_idx].mean().item() for channel_idx in range(0,6)]\n",
    "        if target_test[\"labels\"][idx, 0, label_idx] < threshold:\n",
    "            target_samples_test_class1.append(sample_avg)\n",
    "            target_labels_test_class1.append(target_test[\"labels\"][idx][0])\n",
    "        else:\n",
    "            target_samples_test_class2.append(sample_avg)\n",
    "            target_labels_test_class2.append(target_test[\"labels\"][idx][0])\n",
    "    for idx in range(len(target_train[\"samples\"])):\n",
    "        sample_avg = [target_train[\"samples\"][idx][:,channel_idx].mean().item() for channel_idx in range(0,6)]\n",
    "        if target_train[\"labels\"][idx, 0, label_idx] < threshold:\n",
    "            target_samples_test_class1.append(sample_avg)\n",
    "            target_labels_test_class1.append(target_train[\"labels\"][idx][0])\n",
    "        else:\n",
    "            target_samples_test_class2.append(sample_avg)\n",
    "            target_labels_test_class2.append(target_train[\"labels\"][idx][0])\n",
    "    target_test_class1_df = pd.DataFrame(target_samples_test_class1, columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\", \"NBPMean\", \"SpO2\"])\n",
    "    target_test_class2_df = pd.DataFrame(target_samples_test_class2, columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\", \"NBPMean\", \"SpO2\"])\n",
    "    target_test_labels_class1_df = pd.DataFrame(target_labels_test_class1, columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\", \"NBPMean\", \"SpO2\"])\n",
    "    target_test_labels_class1_df = target_test_labels_class1_df.drop(columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\"])\n",
    "    target_test_labels_class2_df = pd.DataFrame(target_labels_test_class2, columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\", \"NBPMean\", \"SpO2\"])\n",
    "    target_test_labels_class2_df = target_test_labels_class2_df.drop(columns=[\"CVP\", \"HR\", \"NBPSys\", \"NBPDias\"])\n",
    "\n",
    "    distance_measures_features = measure_distance_classwise(distance_function, df1_class1 = source_train_class1_df, \n",
    "                                                                             df1_class2 = source_train_class2_df, df2_class1 = source_test_class1_df, \n",
    "                                                                             df2_class2 = source_test_class2_df, df3_class1 = target_test_class1_df, \n",
    "                                                                             df3_class2= target_test_class2_df)\n",
    "    distance_measures_labels = measure_distance_classwise(distance_function, df1_class1 = source_train_labels_class1_df, \n",
    "                                                                             df1_class2 = source_train_labels_class2_df, df2_class1 = source_test_labels_class1_df, \n",
    "                                                                             df2_class2 = source_test_labels_class2_df, df3_class1 = target_test_labels_class1_df, \n",
    "                                                                             df3_class2= target_test_labels_class2_df)\n",
    "\n",
    "    distance_measures_features_df = pd.DataFrame(distance_measures_features)\n",
    "    distance_measures_features_df.columns = [f\"feature_{col}\" for col in distance_measures_features_df.columns]\n",
    "    distance_measures_features_df = distance_measures_features_df.transpose()\n",
    "\n",
    "    distance_measures_features_df.loc[\"features_sum\"] = distance_measures_features_df.sum()\n",
    "    distance_measures_features_df.loc[\"features_mean\"] = distance_measures_features_df.drop(index=[\"features_sum\"], errors=\"ignore\").mean()\n",
    "    distance_measures_features_df.loc[\"features_max\"] = distance_measures_features_df.drop(index=[\"features_sum\", \"features_mean\"], errors=\"ignore\").max()\n",
    "    \n",
    "    distance_measures_labels_df = pd.DataFrame(distance_measures_labels)\n",
    "    distance_measures_labels_df.columns = [f\"label_{col}\" for col in distance_measures_labels_df.columns]\n",
    "    distance_measures_labels_df = distance_measures_labels_df.transpose()\n",
    "\n",
    "    # append the two dataframes\n",
    "    distance_measures_all_df = pd.concat([distance_measures_features_df, distance_measures_labels_df], axis=0)\n",
    "    distance_measures_all_df.loc[\"features_sum_SpO2_label_sum\"] = distance_measures_features_df.loc[\"features_sum\"] + distance_measures_labels_df.loc[\"label_SpO2\"]\n",
    "    distance_measures_all_df.loc[\"features_mean_SpO2_label_sum\"] = distance_measures_features_df.loc[\"features_mean\"] + distance_measures_labels_df.loc[\"label_SpO2\"]\n",
    "    distance_measures_all_df.loc[\"features_max_SpO2_label_sum\"] = distance_measures_features_df.loc[\"features_max\"] + distance_measures_labels_df.loc[\"label_SpO2\"]\n",
    "    distance_measures_all_df.loc[\"features_sum_NBPMean_label_sum\"] = distance_measures_features_df.loc[\"features_sum\"] + distance_measures_labels_df.loc[\"label_NBPMean\"]\n",
    "    distance_measures_all_df.loc[\"features_mean_NBPMean_label_sum\"] = distance_measures_features_df.loc[\"features_mean\"] + distance_measures_labels_df.loc[\"label_NBPMean\"]\n",
    "    distance_measures_all_df.loc[\"features_max_NBPMean_label_sum\"] = distance_measures_features_df.loc[\"features_max\"] + distance_measures_labels_df.loc[\"label_NBPMean\"]\n",
    "\n",
    "    return distance_measures_all_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769dbd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_distance_source_train_vs_source_test_vs_target_combinations(group_a, group_b, distance_measure):\n",
    "    if distance_measure ==\"ks_2samp\":\n",
    "        distance_function = ks_2samp\n",
    "    elif distance_measure == \"kl_divergence\":\n",
    "        distance_function = kl_divergence_pairwise\n",
    "\n",
    "    distance_measures_all_df = measure_distance_source_train_vs_source_test_vs_target_all(group_a, group_b, distance_function)\n",
    "    distance_measures_all_df.to_csv(f\"./results/distances/{distance_measure}/{group_a}_vs_{group_b}_distance_measures.csv\")\n",
    "    distance_measures_all_df = measure_distance_source_train_vs_source_test_vs_target_all(group_b, group_a, distance_function)\n",
    "    distance_measures_all_df.to_csv(f\"./results/distances/{distance_measure}/{group_b}_vs_{group_a}_distance_measures.csv\")\n",
    "\n",
    "    # class wise \n",
    "    for class_label in [\"Hypoxemia\", \"Hypotension\"]:\n",
    "        distance_measures_all_df = measure_distance_source_train_vs_source_test_vs_target_all_classwise(group_a, group_b, class_label, distance_function)\n",
    "        distance_measures_all_df.to_csv(f\"./results/distances/classwise/{class_label}/{distance_measure}/{group_a}_vs_{group_b}_distance_measures.csv\")\n",
    "        distance_measures_all_df = measure_distance_source_train_vs_source_test_vs_target_all_classwise(group_b, group_a, class_label, distance_function)\n",
    "        distance_measures_all_df.to_csv(f\"./results/distances/classwise/{class_label}/{distance_measure}/{group_b}_vs_{group_a}_distance_measures.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db439298",
   "metadata": {},
   "source": [
    "# Application to Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4f1161",
   "metadata": {},
   "source": [
    "## KS_2Samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da3d634a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmeasure_distance_source_train_vs_source_test_vs_target_combinations\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mno_cardiac_surgery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcardiac_surgery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mks_2samp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m measure_distance_source_train_vs_source_test_vs_target_combinations(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_respiratory_surgery\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrespiratory_surgery\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mks_2samp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m measure_distance_source_train_vs_source_test_vs_target_combinations(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvasopressors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_vasopressors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mks_2samp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m, in \u001b[0;36mmeasure_distance_source_train_vs_source_test_vs_target_combinations\u001b[1;34m(group_a, group_b, distance_measure)\u001b[0m\n\u001b[0;32m      7\u001b[0m distance_measures_all_df \u001b[38;5;241m=\u001b[39m measure_distance_source_train_vs_source_test_vs_target_all(group_a, group_b, distance_function)\n\u001b[0;32m      8\u001b[0m distance_measures_all_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results/distances/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdistance_measure\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgroup_a\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_vs_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgroup_b\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_distance_measures.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m distance_measures_all_df \u001b[38;5;241m=\u001b[39m \u001b[43mmeasure_distance_source_train_vs_source_test_vs_target_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistance_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m distance_measures_all_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results/distances/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdistance_measure\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgroup_b\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_vs_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgroup_a\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_distance_measures.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# class wise \u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 28\u001b[0m, in \u001b[0;36mmeasure_distance_source_train_vs_source_test_vs_target_all\u001b[1;34m(label_source, label_target, distance_function)\u001b[0m\n\u001b[0;32m     26\u001b[0m     target_samples_test\u001b[38;5;241m.\u001b[39mappend(sample_avg)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(target_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m---> 28\u001b[0m     sample_avg \u001b[38;5;241m=\u001b[39m [\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchannel_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m channel_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m6\u001b[39m)]\n\u001b[0;32m     29\u001b[0m     target_samples_test\u001b[38;5;241m.\u001b[39mappend(sample_avg)\n\u001b[0;32m     31\u001b[0m target_test_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(target_samples_test, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCVP\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHR\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNBPSys\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNBPDias\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNBPMean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpO2\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\_methods.py:125\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_float16_result \u001b[38;5;129;01mand\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m         ret \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(ret)\n\u001b[1;32m--> 125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mret\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_float16_result:\n\u001b[0;32m    127\u001b[0m         ret \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(ret \u001b[38;5;241m/\u001b[39m rcount)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "measure_distance_source_train_vs_source_test_vs_target_combinations(\"no_cardiac_surgery\", \"cardiac_surgery\", \"ks_2samp\")\n",
    "measure_distance_source_train_vs_source_test_vs_target_combinations(\"no_respiratory_surgery\", \"respiratory_surgery\", \"ks_2samp\")\n",
    "measure_distance_source_train_vs_source_test_vs_target_combinations(\"vasopressors\", \"no_vasopressors\", \"ks_2samp\")\n",
    "measure_distance_source_train_vs_source_test_vs_target_combinations(\"no_ventilation\", \"ventilation\", \"ks_2samp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd60762",
   "metadata": {},
   "source": [
    "## KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d73fbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_distance_source_train_vs_source_test_vs_target_combinations(\"no_cardiac_surgery\", \"cardiac_surgery\", \"kl_divergence\")\n",
    "measure_distance_source_train_vs_source_test_vs_target_combinations(\"no_respiratory_surgery\", \"respiratory_surgery\", \"kl_divergence\")\n",
    "measure_distance_source_train_vs_source_test_vs_target_combinations(\"vasopressors\", \"no_vasopressors\", \"kl_divergence\")\n",
    "measure_distance_source_train_vs_source_test_vs_target_combinations(\"no_ventilation\", \"ventilation\", \"kl_divergence\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
